{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691aa3f9-db22-41e1-b87e-63a6a4f85e4a",
   "metadata": {},
   "source": [
    "## How to Split Dataset (structured and unstructured) for ML training\n",
    "\n",
    "If you have a single dataset (e.g., all images are in one folder) and you want to split it into train and validation sets automatically, here's how you can do it in Python.\n",
    "\n",
    "This will work if your dataset is unstructured and needs to be divided based on random splitting or a certain percentage (like 80% for training and 20% for validation).\n",
    "\n",
    "#### 1. Steps to Split Dataset (unstructured) into train/ and val/ Folders:\n",
    "Prepare Directory Structure:\n",
    "You need to create a train/ and val/ folder inside the parent folder.\n",
    "\n",
    "Randomly Split Images:\n",
    "We'll randomly assign each image to either the train/ or val/ folder.\n",
    "\n",
    "#### üßë‚Äçüíª Python Code Example to Split Dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d52f2938-e0d7-4c57-8a0b-822b30824895",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(source_dir, train_dir, val_dir, val_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits dataset into train/val directories.\n",
    "\n",
    "    Args:\n",
    "    - source_dir: Path to the source directory containing all images.\n",
    "    - train_dir: Path to the directory where training images will go.\n",
    "    - val_dir: Path to the directory where validation images will go.\n",
    "    - val_size: Fraction of dataset to use for validation.\n",
    "    \"\"\"\n",
    "    # Create directories if they don't exist\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "\n",
    "    # List all files in the source directory\n",
    "    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "    \n",
    "    # Shuffle files to randomize the split\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    # Calculate the number of validation samples\n",
    "    num_val = int(len(files) * val_size)\n",
    "    \n",
    "    # Split the files into training and validation sets\n",
    "    val_files = files[:num_val]\n",
    "    train_files = files[num_val:]\n",
    "    \n",
    "    # Move files to the appropriate directories\n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(source_dir, file), os.path.join(train_dir, file))\n",
    "    \n",
    "    for file in val_files:\n",
    "        shutil.move(os.path.join(source_dir, file), os.path.join(val_dir, file))\n",
    "\n",
    "    print(f\"Split {len(files)} files into {len(train_files)} training and {len(val_files)} validation files.\")\n",
    "\n",
    "# Example usage\n",
    "source_directory = 'dataset/images'  # Your dataset folder with all images\n",
    "train_directory = 'dataset/train'\n",
    "val_directory = 'dataset/val'\n",
    "\n",
    "split_dataset(source_directory, train_directory, val_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99769d-60c4-4b4b-9574-43ebf0d34e6e",
   "metadata": {},
   "source": [
    "#### üîç How It Works:\n",
    "Source Directory: source_directory should contain all the images you want to split. These images are assumed to be unclassified (not in any subfolders).\n",
    "\n",
    "Train/Validation Directories: The script will create train/ and val/ directories and move the images into them.\n",
    "\n",
    "Random Splitting: The images are shuffled randomly, and a percentage of them (default 20% for validation) are moved to the val/ directory. The rest go into the train/ directory.\n",
    "\n",
    "Directory Structure After Split:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64721efc-56d7-4d9c-9552-ca8b1afef916",
   "metadata": {},
   "source": [
    "dataset/\r\n",
    "‚îú‚îÄ‚îÄ train/\r\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\r\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg\r\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\r\n",
    "‚îú‚îÄ‚îÄ val/\r\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img3.jpg\r\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img4.jpg\r\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d643ae3-28ab-4ba5-b15c-4ff2f319179a",
   "metadata": {},
   "source": [
    "#### üìä Customizing the Split:\n",
    "**Validation Size**: You can change the val_size argument to any percentage. For example, val_size=0.2 means 20% of the images go to the validation set, and the rest (80%) go to the training set.\n",
    "\n",
    "**Folder Names**: The code doesn't handle the creation of subfolders for class-based labels (like in your earlier question). If you want to split into class-based folders (e.g., cat/, dog/), you‚Äôll need to modify the script to create these subdirectories based on existing classes in the filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7db96-93b9-4977-9729-4021bc4c2e0e",
   "metadata": {},
   "source": [
    "### 2. Steps for splitting Class-based Folder Structure\n",
    "If your dataset has subfolders with images already classified, you can adjust the above script slightly:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d196d42-56ee-48da-ad2b-45a5f5966c4e",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset_by_class(source_dir, train_dir, val_dir, val_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits dataset into train/val directories based on subfolders (class labels).\n",
    "    \"\"\"\n",
    "    # Create train/val subdirectories for each class\n",
    "    for subfolder in os.listdir(source_dir):\n",
    "        class_folder = os.path.join(source_dir, subfolder)\n",
    "        if os.path.isdir(class_folder):\n",
    "            os.makedirs(os.path.join(train_dir, subfolder), exist_ok=True)\n",
    "            os.makedirs(os.path.join(val_dir, subfolder), exist_ok=True)\n",
    "            \n",
    "            files = [f for f in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, f))]\n",
    "            random.shuffle(files)\n",
    "\n",
    "            # Calculate the number of validation samples\n",
    "            num_val = int(len(files) * val_size)\n",
    "\n",
    "            val_files = files[:num_val]\n",
    "            train_files = files[num_val:]\n",
    "\n",
    "            # Move the images to the corresponding directories\n",
    "            for file in train_files:\n",
    "                shutil.move(os.path.join(class_folder, file), os.path.join(train_dir, subfolder, file))\n",
    "\n",
    "            for file in val_files:\n",
    "                shutil.move(os.path.join(class_folder, file), os.path.join(val_dir, subfolder, file))\n",
    "\n",
    "            print(f\"Class '{subfolder}' split into {len(train_files)} train and {len(val_files)} validation images.\")\n",
    "\n",
    "# Example usage\n",
    "source_directory = 'dataset/images'\n",
    "train_directory = 'dataset/train'\n",
    "val_directory = 'dataset/val'\n",
    "\n",
    "split_dataset_by_class(source_directory, train_directory, val_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a165675-f724-43dd-ae53-2ac979350597",
   "metadata": {},
   "source": [
    "#### What Happens Here:\n",
    "If you have a structure like dataset/images/cat, dataset/images/dog, etc., the script creates corresponding train/cat, val/cat, etc., subdirectories.\n",
    "\n",
    "It moves images within each class to the appropriate folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af8a392-b520-49c9-915c-2e87263c66e6",
   "metadata": {},
   "source": [
    "## How to load custom image set if they are sorted into folder names\n",
    "If your custom image dataset is organized into folders by class names, that‚Äôs perfect ‚Äî both PyTorch and TensorFlow/Keras have built-in tools to handle this directly.\n",
    "\n",
    "#### üìÅ Folder Structure Example"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe410071-b357-4ebd-a99e-8350f0c558b6",
   "metadata": {},
   "source": [
    "dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cat/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img2.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ dog/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img3.jpg\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img4.jpg\n",
    "‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cat/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ dog/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54826303-5847-43c5-8972-db69b693ac29",
   "metadata": {},
   "source": [
    "In this structure:\n",
    "\n",
    "**Folder names** = **class labels** (cat, dog, etc.)\n",
    "\n",
    "**Images are stored inside class folders**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecba4f4-c9d5-437e-af94-a95ebc313483",
   "metadata": {},
   "source": [
    "#### ‚úÖ PyTorch: Use ImageFolder\n",
    "üîß **Code Example**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c707206-8d6b-4aaf-be90-57a102c24d92",
   "metadata": {},
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Step 1: Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Step 2: Load dataset from folders\n",
    "train_dataset = datasets.ImageFolder(root=\"dataset/train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=\"dataset/val\", transform=transform)\n",
    "\n",
    "# Step 3: DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Optional: class name mapping\n",
    "print(train_dataset.classes)        # ['cat', 'dog']\n",
    "print(train_dataset.class_to_idx)   # {'cat': 0, 'dog': 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962a14d-11c1-42f6-a641-8a012894cc64",
   "metadata": {},
   "source": [
    "#### ‚úÖ TensorFlow/Keras: Use image_dataset_from_directory\n",
    "üîß **Code Example**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8032e28f-3b1c-4e3a-877d-bfde99cd989a",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/train\",\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    label_mode='int',  # 'int', 'categorical', or 'binary'\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/val\",\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Optional: Normalize\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2260e-bdb7-4ded-9fc8-854764c5a9b0",
   "metadata": {},
   "source": [
    "You can also check the class names:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1d38f67-fa5b-412e-b26a-5259a84e61c7",
   "metadata": {},
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)  # ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ab938-13a5-43fe-b22b-14a483161f60",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Tips\n",
    "Make sure all images are valid image formats (.jpg, .png, etc.)\n",
    "\n",
    "Folder names should not contain special characters or spaces (ideally)\n",
    "\n",
    "Ensure the same class folders exist in both train/ and val/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b257bdc-2bed-42c1-8bf2-51e2db370b7a",
   "metadata": {},
   "source": [
    "## Load Dataset using Torchvision ImageFolder\n",
    "PyTorch uses torchvision.datasets.ImageFolder to automatically associate folder names with class labels using a simple, intuitive mechanism:\n",
    "\n",
    "#### üîç How ImageFolder Works:\n",
    "When you initialize ImageFolder like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f536558-239d-4ba3-86c0-6d08dbd4a678",
   "metadata": {},
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "dataset = ImageFolder(root='dataset/train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743f3ce-eeb5-44a6-b4c4-56665790fa09",
   "metadata": {},
   "source": [
    "Here's what happens internally:\n",
    "\n",
    "**Scans Subfolders** under 'dataset/train':\n",
    "\n",
    "For example: cat/, dog/, car/\n",
    "\n",
    "**Sorts Folder Names Alphabetically:**\n",
    "\n",
    "Let's say your folders are ['cat', 'car', 'dog'], then:\n",
    "\n",
    "- 'car' ‚Üí label 0\n",
    "\n",
    "- 'cat' ‚Üí label 1\n",
    "\n",
    "- 'dog' ‚Üí label 2\n",
    "\n",
    "**Maps Images to Labels:**\n",
    "\n",
    "- Every image in dataset/train/cat/ will be given label 1 (from 'cat')\n",
    "\n",
    "- Images in dataset/train/dog/ will be labeled 2, and so on\n",
    "\n",
    "You can view the mapping:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b327f0e-289b-4c15-899a-c27a4dbebf49",
   "metadata": {},
   "source": [
    "print(dataset.class_to_idx)\n",
    "# Output: {'car': 0, 'cat': 1, 'dog': 2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8a237-306d-4a24-9e30-73df86dea76a",
   "metadata": {},
   "source": [
    "Each item returned by dataset[i] is:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c0f7db1-2770-4583-bb87-67cc87c70324",
   "metadata": {},
   "source": [
    "(image_tensor, label_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f258d1-fef9-4eaa-bd19-b0b675f79d21",
   "metadata": {},
   "source": [
    "#### ‚úÖ Summary:\n",
    "\n",
    "| Folder Name| Label |\n",
    "|-----------|-----|\n",
    "| car/\t| 0 |\n",
    "| cat/\t| 1 |\n",
    "| dog/\t| 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8915b2-4228-4fbe-b581-367f5ebbe274",
   "metadata": {},
   "source": [
    "The folder name becomes the class, and the index assigned is based on alphabetical order, unless you customize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0343d44-6f33-40c9-b647-4a336eeceb31",
   "metadata": {},
   "source": [
    "## How to load custom image dataset with their names as classification labels\n",
    "if your image filenames are labels (e.g., cat.jpg, dog.jpg, car.png, etc.) and not organized into folders, you can still load and use them for training. Below are ways to do this in PyTorch and TensorFlow/Keras.\n",
    "\n",
    "#### üîç Assumptions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "746e5395-2c4e-475e-93b6-393dad0d3996",
   "metadata": {},
   "source": [
    "dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cat.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ dog.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ car.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6000c-5720-4941-83d7-100d21a8ea81",
   "metadata": {},
   "source": [
    "Each file's **name (or part of it)** is the **label** (e.g., dog.jpg ‚Üí label: \"dog\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1830a2-6fe4-4cfd-99ce-64fba0cf1d78",
   "metadata": {},
   "source": [
    "#### üß† PyTorch Custom Dataset\n",
    "You'll need to write a custom Dataset class to parse labels from filenames."
   ]
  },
  {
   "cell_type": "raw",
   "id": "faa2e1f0-0a9b-45f4-8d31-fc6a4ba0a34f",
   "metadata": {},
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "        # Extract unique labels from filenames\n",
    "        self.labels = sorted(list(set([f.split('.')[0] for f in self.image_files])))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.labels)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        label_name = img_name.split('.')[0]\n",
    "        label = self.label_to_idx[label_name]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee92fb5-2cff-4108-b514-741ca2a7db28",
   "metadata": {},
   "source": [
    "#### üß™ Usage:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81e7203c-5eba-4ac5-b2ea-c2aa7a670e9d",
   "metadata": {},
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(\"dataset/train\", transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b65d67-0190-42e6-b98f-31a0ea193be1",
   "metadata": {},
   "source": [
    "#### üåü TensorFlow/Keras (Using Filenames as Labels)\n",
    "TensorFlow doesn't handle this directly, so you must map filenames to labels yourself.\n",
    "\n",
    "#### üìÅ Step 1: Create a list of filenames and labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12d16516-f075-45c3-bb92-e2463d168204",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "image_dir = \"dataset/train\"\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Build label set from filenames\n",
    "for fname in os.listdir(image_dir):\n",
    "    if fname.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        label = fname.split('.')[0]  # 'dog.jpg' ‚Üí 'dog'\n",
    "        image_paths.append(os.path.join(image_dir, fname))\n",
    "        labels.append(label)\n",
    "\n",
    "# Map labels to integers\n",
    "unique_labels = sorted(set(labels))\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "numeric_labels = [label_to_index[label] for label in labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7abb28-1aca-4b3e-a033-02f8818e953b",
   "metadata": {},
   "source": [
    "#### üì¶ Step 2: Create TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8ecc194-a262-4aeb-aeb7-855a7948ecae",
   "metadata": {},
   "source": [
    "def process_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "ds = tf.data.Dataset.from_tensor_slices((image_paths, numeric_labels))\n",
    "ds = ds.map(process_image).batch(32).shuffle(buffer_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290711e-ffd8-4345-b445-418ad902c5c2",
   "metadata": {},
   "source": [
    "#### ‚úÖ Summary\n",
    "\n",
    "| Framework\t| Method |\n",
    "|-----------|--------|\n",
    "|PyTorch\t| Create a custom Dataset that reads labels from filenames |\n",
    "|TensorFlow\t| Create a tf.data.Dataset manually from image paths and filename-based labels|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2e0fc-f079-49c2-b429-5f062d39065a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
